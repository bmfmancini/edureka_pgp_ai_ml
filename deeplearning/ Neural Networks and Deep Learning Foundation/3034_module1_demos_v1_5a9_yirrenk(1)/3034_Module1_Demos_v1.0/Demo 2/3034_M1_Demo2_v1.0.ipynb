{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Demo 2 - Train a basic MLP on the MNIST dataset\n",
        "\n",
        "\n",
        "## **Scenario: Handwritten Digit Recognition**\n",
        "A startup working on digitizing old handwritten documents wants to build a fast, reliable model to automatically recognize handwritten digits (0â€“9).\n",
        "They aim to use a simple Multilayer Perceptron (MLP) model to classify images from the MNIST dataset (which contains 28x28 grayscale images of handwritten digits).\n",
        "Since this is an early prototype, the focus is on building and training a basic MLP without using complex architectures like CNNs.\n",
        "\n",
        "## **Objectives:**\n",
        "* Build and train a basic Multilayer Perceptron (MLP) model from scratch (or using PyTorch/Keras basic layers).\n",
        "\n",
        "* Achieve at least 90% training accuracy.\n",
        "\n",
        "* Understand the impact of hidden layers and activation functions (like ReLU) on model performance.\n",
        "\n",
        "* Evaluate the model using metrics such as accuracy and loss curves."
      ],
      "metadata": {
        "id": "ESFN2p3UFmL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Required Libraries\n",
        "Import libraries for building the model, loading data, and evaluation."
      ],
      "metadata": {
        "id": "nWkv-lgBF3ya"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20RI-cS3FkS1"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load and Prepare the MNIST Dataset\n",
        "Load the MNIST handwritten digit dataset from Keras datasets.\n",
        "\n",
        "Normalize pixel values to range [0, 1] for faster convergence.\n"
      ],
      "metadata": {
        "id": "fqb-8OWpF55k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "# Normalize the pixel values\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "metadata": {
        "id": "cMP0sCkqGBoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Flatten the Images\n",
        "Flatten each 28x28 image into a 784-dimensional vector.\n",
        "\n",
        "This is necessary because MLPs expect 1D feature vectors as input."
      ],
      "metadata": {
        "id": "BLfTxgh2GHBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)"
      ],
      "metadata": {
        "id": "OEdkfsEFGDeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Build the MLP Model\n",
        " Create a simple MLP with one hidden layer using ReLU activation.\n",
        "\n",
        " Output layer has 10 units (one for each digit) with softmax activation."
      ],
      "metadata": {
        "id": "YvnVLbD3GOpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),  # Hidden layer with 128 neurons\n",
        "    layers.Dense(10, activation='softmax')                     # Output layer with 10 classes\n",
        "])"
      ],
      "metadata": {
        "id": "mWTM7c1MGJ8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Compile the Model\n",
        "Define the optimizer, loss function, and evaluation metric for training."
      ],
      "metadata": {
        "id": "x-w5V7aKJEDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',                          # Adam optimizer for faster convergence\n",
        "    loss='sparse_categorical_crossentropy',     # Suitable loss for multi-class classification\n",
        "    metrics=['accuracy']                        # Evaluate using accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "fbc3sDfeJDDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Train the Model\n",
        "Train the model on the training data for 10 epochs.\n",
        "\n",
        " Store training history to visualize learning curves."
      ],
      "metadata": {
        "id": "MH7ObuStGTLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=10, validation_split=0.1)"
      ],
      "metadata": {
        "id": "jVT2jjgjGP1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 8: Plot Accuracy and Loss Curves\n",
        " Visualize how model performance improved during training."
      ],
      "metadata": {
        "id": "xEmT1kHmGYH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy curve\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Loss curve\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xPgXq2IUGVx8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}