{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Demo 2 - Sentiment Analysis using CNN + Hyperparameter Tuning\n",
        "\n",
        "##**Scenario**\n",
        "You're building a sentiment analysis model to classify movie reviews as positive or negative using the IMDB dataset. You'll apply regularization, gradient clipping, and hyperparameter tuning using Keras Tuner, and visualize the training process with TensorBoard.\n",
        "\n",
        "## **Objective**\n",
        "* Use a CNN-based architecture for text classification\n",
        "\n",
        "* Tune hyperparameters like embedding size, filters, kernel size, dropout, learning rate\n",
        "\n",
        "* Apply gradient clipping and dropout\n",
        "* Visualize training using TensorBoard\n",
        "\n",
        "* Evaluate model on test data\n"
      ],
      "metadata": {
        "id": "k9_e6CoRaVco"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Import Required Libraries\n",
        "Import all required libraries including Keras Tuner and preprocessing tools."
      ],
      "metadata": {
        "id": "y78BVbipbWcO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWk8VHbCTWrt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras_tuner.tuners import RandomSearch # This line should now work after installing the package."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Load and Preprocess IMDB Dataset\n",
        "Load movie reviews, tokenize them, and pad to uniform sequence length."
      ],
      "metadata": {
        "id": "U6OY9WnQbcjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "maxlen = 200\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ],
      "metadata": {
        "id": "tscrZxuWbdFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Define 1D CNN Model for Hyperparameter Tuning\n",
        "Defines a tunable 1D CNN model using embedding, convolution, pooling, dropout, and sigmoid output.\n"
      ],
      "metadata": {
        "id": "mVp503gvdgUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Embedding(input_dim=vocab_size,\n",
        "                               output_dim=hp.Int('embed_dim', 32, 128, step=32),\n",
        "                               input_length=maxlen))\n",
        "    model.add(layers.Conv1D(filters=hp.Int('filters', 32, 128, step=32),\n",
        "                            kernel_size=hp.Choice('kernel_size', [3, 5]),\n",
        "                            activation='relu'))\n",
        "    model.add(layers.GlobalMaxPooling1D())\n",
        "    model.add(layers.Dropout(hp.Choice('dropout', [0.2, 0.3, 0.5])))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4]),\n",
        "            clipnorm=1.0  # Gradient clipping\n",
        "        ),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "Tr6KFeSMdg6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Set Up TensorBoard and EarlyStopping Callbacks\n",
        "Enables training monitoring and stops training early if validation doesnâ€™t improve."
      ],
      "metadata": {
        "id": "ff1_BAVcdpkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = \"logs/demo2\"\n",
        "tensorboard_cb = callbacks.TensorBoard(log_dir=log_dir)\n",
        "early_stop_cb = callbacks.EarlyStopping(patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "JuyionIVdnWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Run Random Search with Keras Tuner\n",
        "Automatically tests multiple hyperparameter combinations and logs results."
      ],
      "metadata": {
        "id": "ExOilyaId0CN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuner_dir',\n",
        "    project_name='sentiment_analysis'\n",
        ")\n",
        "\n",
        "tuner.search(x_train, y_train, epochs=5, validation_split=0.2,\n",
        "             callbacks=[tensorboard_cb, early_stop_cb], batch_size=64)"
      ],
      "metadata": {
        "id": "rM0BgbEMdxDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Retrieve the Best Model and Evaluate\n",
        "Fetch and evaluate the best model found during tuning.\n"
      ],
      "metadata": {
        "id": "zCp8iteddw2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "k02MfIvwd5Xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 7: Launch TensorBoard in Google Colab\n",
        "Launches TensorBoard in notebook to view training curves, histograms, and scalar logs."
      ],
      "metadata": {
        "id": "4gsigTdViAQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/demo2"
      ],
      "metadata": {
        "id": "6PPUvLBuh_Ul"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}