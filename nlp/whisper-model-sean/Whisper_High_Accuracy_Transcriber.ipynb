{"nbformat":4,"nbformat_minor":5,"metadata":{"colab":{"provenance":[],"history_visible":true,"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"title"},"source":["# üéß Whisper High‚ÄëAccuracy Transcriber (Free)\n","\n","**What this does:**\n","- Upload a long audio file (MP3/WAV/M4A/etc.)\n","- Transcribe with **OpenAI Whisper ‚Äî `large` model** (most accurate)\n","- Auto‚Äëdetects language by default\n","- Exports **TXT**, **SRT** (subtitles), and **VTT**\n","\n","**How to use:**\n","1. Run each cell top‚Äëto‚Äëbottom.\n","2. Upload your audio when prompted.\n","3. Wait for transcription to finish, then download the files.\n","\n","> Tip: If a GPU is available (Runtime ‚Üí Change runtime type ‚Üí T4/L4/A100), it will be much faster. CPU also works; it just takes longer.\n"],"id":"title"},{"cell_type":"code","metadata":{"id":"install","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768014891852,"user_tz":300,"elapsed":204812,"user":{"displayName":"Sean Mancini","userId":"16613485068153021290"}},"outputId":"79a89706-f4a4-4cb1-9075-cd67f180d4f7"},"source":["%%bash\n","echo \"Checking GPU (ok if none is shown)‚Ä¶\" >&2\n","nvidia-smi || true\n","echo \"\\nInstalling dependencies‚Ä¶\" >&2\n","pip -q install --upgrade pip >/dev/null 2>&1\n","pip -q install openai-whisper==20231117 >/dev/null 2>&1\n","apt -y -qq update >/dev/null 2>&1 || true\n","apt -y -qq install ffmpeg >/dev/null 2>&1\n","echo \"Done.\"\n"],"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Jan 10 03:11:27 2026       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   41C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n","Done.\n"]},{"output_type":"stream","name":"stderr","text":["Checking GPU (ok if none is shown)‚Ä¶\n","\\nInstalling dependencies‚Ä¶\n"]}],"execution_count":1,"id":"install"},{"cell_type":"code","metadata":{"id":"settings","executionInfo":{"status":"ok","timestamp":1768015017742,"user_tz":300,"elapsed":21,"user":{"displayName":"Sean Mancini","userId":"16613485068153021290"}}},"source":["# üîß Settings (change if needed)\n","MODEL_NAME = \"medium\"          # Most accurate open-source Whisper model\n","FORCE_LANGUAGE = \"en\"           # e.g., \"en\" or \"Portuguese\". Leave blank \"\" to auto-detect\n","TASK = \"transcribe\"            # or \"translate\" to translate non-English ‚Üí English\n","TEMPERATURE = 0.0              # 0.0 = most deterministic\n","FP16 = True                    # Set False for CPU-only / errors with half precision\n","PRINT_SEGMENTS = True          # Print timecoded segments to the notebook output\n"],"execution_count":2,"id":"settings","outputs":[]},{"cell_type":"code","metadata":{"id":"upload","colab":{"base_uri":"https://localhost:8080/","height":110},"outputId":"4c90d71a-b3dd-4720-9437-213727f4cb6e","executionInfo":{"status":"ok","timestamp":1768015218328,"user_tz":300,"elapsed":199042,"user":{"displayName":"Sean Mancini","userId":"16613485068153021290"}}},"source":["from google.colab import files\n","import os\n","\n","print(\"üì§ Choose your audio file to upload (mp3/wav/m4a/etc.)‚Ä¶\")\n","uploaded = files.upload()\n","assert uploaded, \"No file was uploaded.\"\n","AUDIO_PATH = next(iter(uploaded))\n","print(f\"Uploaded: {AUDIO_PATH} ‚Ä¢ Size: {os.path.getsize(AUDIO_PATH)/1e6:.2f} MB\")\n"],"execution_count":3,"id":"upload","outputs":[{"output_type":"stream","name":"stdout","text":["üì§ Choose your audio file to upload (mp3/wav/m4a/etc.)‚Ä¶\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-69555df9-b9c4-44a5-b4d9-a6ed2894bfc2\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-69555df9-b9c4-44a5-b4d9-a6ed2894bfc2\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving machine_translation.mp3 to machine_translation.mp3\n","Uploaded: machine_translation.mp3 ‚Ä¢ Size: 114.05 MB\n"]}]},{"cell_type":"code","metadata":{"id":"transcribe","colab":{"base_uri":"https://localhost:8080/"},"outputId":"387a1887-dab7-46b8-8215-dac728bdf7eb"},"source":["import whisper, torch, os, math\n","from datetime import timedelta\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","if device == \"cpu\":\n","    # CPU can't use fp16\n","    FP16 = False\n","print(\"üñ•Ô∏è Using device:\", device)\n","\n","print(\"üì• Loading model:\", MODEL_NAME)\n","model = whisper.load_model(MODEL_NAME, device=device)\n","\n","kwargs = {\n","    \"task\": TASK,\n","    \"temperature\": TEMPERATURE,\n","    \"fp16\": FP16,\n","}\n","if FORCE_LANGUAGE.strip():\n","    kwargs[\"language\"] = FORCE_LANGUAGE.strip()\n","\n","print(\"üìù Transcribing‚Ä¶ this can take a while for long files.\")\n","result = model.transcribe(AUDIO_PATH, **kwargs)\n","text = result.get(\"text\", \"\").strip()\n","\n","base = os.path.splitext(os.path.basename(AUDIO_PATH))[0]\n","txt_path = f\"{base}.txt\"\n","with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n","    f.write(text)\n","print(\"‚úÖ Transcript saved:\", txt_path)\n","\n","def format_timestamp(seconds: float, always_include_hours: bool = True, decimal_marker: str = ','):\n","    if seconds < 0:\n","        seconds = 0\n","    milliseconds = round(seconds * 1000.0)\n","    hours = milliseconds // 3_600_000\n","    milliseconds -= hours * 3_600_000\n","    minutes = milliseconds // 60_000\n","    milliseconds -= minutes * 60_000\n","    secs = milliseconds // 1000\n","    milliseconds -= secs * 1000\n","    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n","    return f\"{hours_marker}{minutes:02d}:{secs:02d}{decimal_marker}{milliseconds:03d}\"\n","\n","srt_path = f\"{base}.srt\"\n","with open(srt_path, \"w\", encoding=\"utf-8\") as srt:\n","    for i, seg in enumerate(result.get(\"segments\", []), start=1):\n","        start = format_timestamp(seg['start'], always_include_hours=True, decimal_marker=',')\n","        end = format_timestamp(seg['end'], always_include_hours=True, decimal_marker=',')\n","        srt.write(f\"{i}\\n{start} --> {end}\\n{seg['text'].strip()}\\n\\n\")\n","print(\"üé¨ Subtitles saved:\", srt_path)\n","\n","vtt_path = f\"{base}.vtt\"\n","with open(vtt_path, \"w\", encoding=\"utf-8\") as vtt:\n","    vtt.write(\"WEBVTT\\n\\n\")\n","    for seg in result.get(\"segments\", []):\n","        start = format_timestamp(seg['start'], always_include_hours=True, decimal_marker='.')\n","        end = format_timestamp(seg['end'], always_include_hours=True, decimal_marker='.')\n","        vtt.write(f\"{start} --> {end}\\n{seg['text'].strip()}\\n\\n\")\n","print(\"üìù WebVTT saved:\", vtt_path)\n","\n","if PRINT_SEGMENTS:\n","    for seg in result.get(\"segments\", []):\n","        print(f\"[{format_timestamp(seg['start'])} ‚Üí {format_timestamp(seg['end'])}] {seg['text'].strip()}\")\n"],"execution_count":null,"id":"transcribe","outputs":[{"output_type":"stream","name":"stdout","text":["üñ•Ô∏è Using device: cuda\n","üì• Loading model: medium\n"]},{"output_type":"stream","name":"stderr","text":["100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.42G/1.42G [00:31<00:00, 48.1MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["üìù Transcribing‚Ä¶ this can take a while for long files.\n"]}]},{"cell_type":"code","metadata":{"id":"download","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1766287882079,"user_tz":300,"elapsed":83,"user":{"displayName":"Sean Mancini","userId":"16613485068153021290"}},"outputId":"50448b7c-c642-4226-92cf-be98ae7b48f5"},"source":["from google.colab import files\n","print(\"‚¨áÔ∏è Preparing downloads‚Ä¶\")\n","for ext in (\".txt\", \".srt\", \".vtt\"):\n","    path = f\"{os.path.splitext(os.path.basename(AUDIO_PATH))[0]}{ext}\"\n","    if os.path.exists(path):\n","        files.download(path)\n","print(\"All set. If your downloads didn't auto-start, open the Files tab (left) and right-click to download.\")\n"],"execution_count":null,"id":"download","outputs":[{"output_type":"stream","name":"stdout","text":["‚¨áÔ∏è Preparing downloads‚Ä¶\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_42ef7673-e705-42ab-9a62-b814116ee488\", \"tokenization_nlp_class_4.txt\", 106962)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_e6e8cb80-faba-4756-b916-bb25d0b7b6cb\", \"tokenization_nlp_class_4.srt\", 158416)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_48e27bb8-62db-498f-985a-709b9fbb895c\", \"tokenization_nlp_class_4.vtt\", 152231)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["All set. If your downloads didn't auto-start, open the Files tab (left) and right-click to download.\n"]}]},{"cell_type":"markdown","metadata":{"id":"tips"},"source":["### üß© Troubleshooting & Tips\n","- **Runtime crashed / out of memory?** Use a GPU runtime (Runtime ‚Üí Change runtime type ‚Üí GPU) or switch to a smaller model (e.g., `medium`).\n","- **Wrong language detected?** Set `FORCE_LANGUAGE = \"en\"` (or your language) in the Settings cell.\n","- **Punctuation/Names not perfect?** That‚Äôs normal for automated ASR. You can lightly edit the TXT afterward.\n","- **Very long files?** Whisper can handle multi-hour files. If you still hit limits, you can split with FFmpeg:\n","  ```bash\n","  ffmpeg -i long_audio.mp3 -f segment -segment_time 1800 -c copy part_%03d.mp3\n","  ```\n","- **Translate to English?** Set `TASK = \"translate\"`.\n"],"id":"tips"}]}