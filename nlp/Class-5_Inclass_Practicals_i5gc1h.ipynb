{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ba6fa49-ce02-4488-aee4-32097bb9ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ranjith/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ranjith/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/ranjith/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP Libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# SKLearn Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a83d20-5f4a-477b-8697-e91d02b60fd7",
   "metadata": {},
   "source": [
    "# Load Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a41b7a7-573a-481f-bc10-359e7e17a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km²)</th>\n",
       "      <th>Density (P/Km²)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>morning</td>\n",
       "      <td>46-60</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>77265</td>\n",
       "      <td>470.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>60-70</td>\n",
       "      <td>Angola</td>\n",
       "      <td>32866272</td>\n",
       "      <td>1246700.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID  ... Density (P/Km²)\n",
       "0  cb774db0d1  ...              60\n",
       "1  549e992a42  ...             105\n",
       "2  088c60f138  ...              18\n",
       "3  9642c003ef  ...             164\n",
       "4  358bd9e861  ...              26\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv', encoding='latin1')\n",
    "test_data = pd.read_csv('test.csv', encoding='latin1')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1dac6a-8a4a-47e4-852b-1564ee86cef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52a29a1-dc81-42ef-945c-4f77789edd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4815, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1809b92-827a-4e9a-ada4-fe38d215332c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral     11118\n",
       "positive     8582\n",
       "negative     7781\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07e22c-a58d-4de0-adf7-e2bdec51c0b6",
   "metadata": {},
   "source": [
    "# NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "124a2423-f4fa-4ced-934c-b3d3f56aad62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "658ccbe1-358b-4905-bde6-3fe80388b80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{re.escape(string.punctuation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2d70b8-4129-467e-9951-25cf2dad46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b86bea22-de36-4274-b15d-9cc6db0887b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['cleaned_text'] = train_data['text'].apply(clean_text)\n",
    "test_data['cleaned_text'] = test_data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfe8756b-6b22-4b40-83fa-15c6dd19dee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        id have responded if i were going\n",
       "1               sooo sad i will miss you here in san diego\n",
       "2                                   my boss is bullying me\n",
       "3                            what interview leave me alone\n",
       "4         sons of  why couldnt they put them on the rel...\n",
       "                               ...                        \n",
       "27476     wish we could come see u on denver  husband l...\n",
       "27477     ive wondered about rake to  the client has ma...\n",
       "27478     yay good for both of you enjoy the break  you...\n",
       "27479                                but it was worth it  \n",
       "27480       all this flirting going on  the atg smiles ...\n",
       "Name: cleaned_text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['cleaned_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14635633-31a3-477e-bce5-77e1cc208f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords and Lemmatization apply\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "483bf82b-5e6f-4f5b-b3ae-25bf77828045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['he', 'go', 'market']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = ['he', 'go','market']\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0dc9a2d-c396-401a-a975-3233527adc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'he go market'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "363cecc1-1a89-446e-81f2-dbc17e6fd8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfe19755-0dd5-4afe-8988-a08d2d05c59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b84fd6ed-3393-46c0-ab2c-c1b7f2ccf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['processed_text'] = train_data['cleaned_text'].apply(preprocess_text)\n",
    "test_data['processed_text'] = test_data['cleaned_text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "411046f3-784c-42c2-b059-67b3562971d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       id responded going\n",
       "1                                  sooo sad miss san diego\n",
       "2                                             bos bullying\n",
       "3                                    interview leave alone\n",
       "4                   son couldnt put release already bought\n",
       "                               ...                        \n",
       "27476    wish could come see u denver husband lost job ...\n",
       "27477    ive wondered rake client made clear net dont f...\n",
       "27478    yay good enjoy break probably need hectic week...\n",
       "27479                                                worth\n",
       "27480                     flirting going atg smile yay hug\n",
       "Name: processed_text, Length: 27481, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['processed_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a221c-d5d3-4751-a39c-45978696d046",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77f152a3-285f-432a-af18-84a81df2e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data['processed_text']\n",
    "y = train_data['sentiment']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133c3c6a-17c1-4ac7-a86b-7f78c2f73da4",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b622127b-9c88-4c26-84d4-1f7f9c1c7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_train_vec = tfidf.fit_transform(X_train)\n",
    "X_val_vec = tfidf.transform(X_val)\n",
    "\n",
    "X_test_vec = tfidf.transform(test_data['processed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e036b140-bcc7-4327-af3d-c46633a23aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21984x22409 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 153969 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975753d-6658-4435-85e9-6dba92c03d6b",
   "metadata": {},
   "source": [
    "# Model Explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebab45d-8b9c-4e68-bc3a-17d65f967ab1",
   "metadata": {},
   "source": [
    "## Random Forest Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6c0f7b1-fa18-4471-af48-8dcedc77f3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Model: RandomForestClassifier*************\n",
      "Accuracy_Score: \n",
      " 0.6958340913225396\n",
      "Classification Repot: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.59      0.66      1636\n",
      "     neutral       0.64      0.73      0.68      2185\n",
      "    positive       0.73      0.75      0.74      1676\n",
      "\n",
      "    accuracy                           0.70      5497\n",
      "   macro avg       0.71      0.69      0.70      5497\n",
      "weighted avg       0.70      0.70      0.69      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=32)\n",
    "rf.fit(X_train_vec, y_train)\n",
    "y_pred_rf = rf.predict(X_val_vec)\n",
    "\n",
    "print('********** Model: RandomForestClassifier*************')\n",
    "\n",
    "print('Accuracy_Score: \\n', accuracy_score(y_val, y_pred_rf))\n",
    "\n",
    "print('Classification Repot: \\n', classification_report(y_val, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5dec8-6f71-4758-b734-3fb77e82dc2e",
   "metadata": {},
   "source": [
    "## Navie Bayer Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4129ad0-f412-49ea-b467-16ea4dfaaf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Model: Naive Bayes Classifier*************\n",
      "Accuracy_Score: \n",
      " 0.6132435874113152\n",
      "Classification Repot: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.40      0.54      1636\n",
      "     neutral       0.52      0.82      0.64      2185\n",
      "    positive       0.74      0.55      0.63      1676\n",
      "\n",
      "    accuracy                           0.61      5497\n",
      "   macro avg       0.69      0.59      0.60      5497\n",
      "weighted avg       0.67      0.61      0.61      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vec, y_train)\n",
    "y_pred_nb = nb.predict(X_val_vec)\n",
    "\n",
    "print('********** Model: Naive Bayes Classifier*************')\n",
    "\n",
    "print('Accuracy_Score: \\n', accuracy_score(y_val, y_pred_nb))\n",
    "\n",
    "print('Classification Repot: \\n', classification_report(y_val, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ccb2ef-ce31-4983-9976-ffc7641d6d6e",
   "metadata": {},
   "source": [
    "## SVM Classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19dfb5f0-e401-4a1e-b02a-009c46749db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** Model: SVM Classifier*************\n",
      "Accuracy_Score: \n",
      " 0.6690922321266145\n",
      "Classification Repot: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.63      0.66      1636\n",
      "     neutral       0.62      0.67      0.65      2185\n",
      "    positive       0.72      0.71      0.71      1676\n",
      "\n",
      "    accuracy                           0.67      5497\n",
      "   macro avg       0.68      0.67      0.67      5497\n",
      "weighted avg       0.67      0.67      0.67      5497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "svm.fit(X_train_vec, y_train)\n",
    "y_pred_svm = svm.predict(X_val_vec)\n",
    "\n",
    "print('********** Model: SVM Classifier*************')\n",
    "\n",
    "print('Accuracy_Score: \\n', accuracy_score(y_val, y_pred_svm))\n",
    "\n",
    "print('Classification Repot: \\n', classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c86769e3-f363-4964-bdff-0566cccaf6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19234     neutral\n",
       "10375    negative\n",
       "8495     positive\n",
       "3483     negative\n",
       "6877      neutral\n",
       "           ...   \n",
       "3119      neutral\n",
       "22194     neutral\n",
       "4326     positive\n",
       "15582     neutral\n",
       "18965    negative\n",
       "Name: sentiment, Length: 5497, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f44c3df-a922-416b-84c1-a53b9a1ec484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'negative', 'positive', ..., 'positive', 'negative',\n",
       "       'negative'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96b5b4c-53a9-474b-8d5c-56f21bebc723",
   "metadata": {},
   "source": [
    "# Save the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5d68aba-0ade-4013-b69b-5038d027c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_model_v1.pkl', 'wb') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8636642-eb02-4d84-aed3-df52d07c1e06",
   "metadata": {},
   "source": [
    "# Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec2f7fa3-9881-407b-97bd-f63f2e633156",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment_model_v1.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b078e3c-95c6-4be2-a3e5-32c32d15c2e6",
   "metadata": {},
   "source": [
    "# Predict Using the Latest Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3ee61d3-67ec-43fb-973e-16adae05e31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "sample_text = ['This movie was absolutely fantastic!']\n",
    "\n",
    "sample_cleaned = [preprocess_text(clean_text(t)) for t in sample_text]\n",
    "sample_vec = tfidf.transform(sample_cleaned)\n",
    "\n",
    "print('Predicted Sentiment:', loaded_model.predict(sample_vec)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ed1b7-ae86-45f9-a0ea-1764d8bcb0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
